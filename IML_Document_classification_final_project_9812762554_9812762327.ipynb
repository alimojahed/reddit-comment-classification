{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G0k61iQoQlp"
      },
      "source": [
        "# Introduction to Machine Learning\n",
        "\n",
        "## Final Project\n",
        "\n",
        "## Document Classification\n",
        "\n",
        "### Ali Mojahed - 9812762554\n",
        "### Mahya Ehsanimehr - 9812762327\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCKI3iDJeT0_"
      },
      "source": [
        "# 1. Download Datasets and Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbGIUry0efLE"
      },
      "source": [
        "## 1.1. Download Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDNXeB80rY_x",
        "outputId": "3d97c097-703f-4b5d-ea5a-b89ea1ffce1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-05 06:59:38--  https://www.dropbox.com/s/d4kee6t0e9l8e1r/data.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/d4kee6t0e9l8e1r/data.zip [following]\n",
            "--2022-07-05 06:59:38--  https://www.dropbox.com/s/raw/d4kee6t0e9l8e1r/data.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uccfc57de5410deefc5c61ab8a0e.dl.dropboxusercontent.com/cd/0/inline/BoeMtGet5zGsgGwLYlQnMBcMjTT0pB0ynYMYPf5Fbbm5BHlmgyAUuCZ6b-y0pAjaP_Cqbtoc5i421g0yQPrqljBU6W3TuRog68UW88_hUgyHx5YZKqRFwHM5ZLRovgAbjdD90_uakckq32TBilSlb7OILmIRVM-D-08qAA8QsbgSjg/file# [following]\n",
            "--2022-07-05 06:59:38--  https://uccfc57de5410deefc5c61ab8a0e.dl.dropboxusercontent.com/cd/0/inline/BoeMtGet5zGsgGwLYlQnMBcMjTT0pB0ynYMYPf5Fbbm5BHlmgyAUuCZ6b-y0pAjaP_Cqbtoc5i421g0yQPrqljBU6W3TuRog68UW88_hUgyHx5YZKqRFwHM5ZLRovgAbjdD90_uakckq32TBilSlb7OILmIRVM-D-08qAA8QsbgSjg/file\n",
            "Resolving uccfc57de5410deefc5c61ab8a0e.dl.dropboxusercontent.com (uccfc57de5410deefc5c61ab8a0e.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uccfc57de5410deefc5c61ab8a0e.dl.dropboxusercontent.com (uccfc57de5410deefc5c61ab8a0e.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BodO7PA-aLMZlvlmX1Qa_Y4dRt33M97u2CvY1QcxCUOc597HjToaOu46rwmUPkBYfNeeknTqHoRYPGCWlJd70dfsFoW9Ta1EYWTBO6VCalomuMhAf_JBkoVcE4uBE-FF6tEu2_vK5Wbj5rNv1432s2-zMxchabSlqkoxUMezelO9kzUxu_wSZXAy5iaumQFW0JWb_G2qfdm_K9VfjD8IZ7Jn0vy5Qv_K37Jj00-lrIo71dOCyxcwIiTV_s9AbI5L3j2bEtS3APA8Tpy8-ZPyfrG1qRPFyJ3RpZeK5WMfgiipQpbkZF6Tx6O2R0wQ3nr57jTpsMYoprI6xZUnz_wqn4WYY8PX15jMnLeHZgmpQd8Ua5v0u1rV4It63lM0CfwvcS85wHTRnz08QntCeoR8gA-j9SRVQc_X45Nnbpshdvct2A/file [following]\n",
            "--2022-07-05 06:59:38--  https://uccfc57de5410deefc5c61ab8a0e.dl.dropboxusercontent.com/cd/0/inline2/BodO7PA-aLMZlvlmX1Qa_Y4dRt33M97u2CvY1QcxCUOc597HjToaOu46rwmUPkBYfNeeknTqHoRYPGCWlJd70dfsFoW9Ta1EYWTBO6VCalomuMhAf_JBkoVcE4uBE-FF6tEu2_vK5Wbj5rNv1432s2-zMxchabSlqkoxUMezelO9kzUxu_wSZXAy5iaumQFW0JWb_G2qfdm_K9VfjD8IZ7Jn0vy5Qv_K37Jj00-lrIo71dOCyxcwIiTV_s9AbI5L3j2bEtS3APA8Tpy8-ZPyfrG1qRPFyJ3RpZeK5WMfgiipQpbkZF6Tx6O2R0wQ3nr57jTpsMYoprI6xZUnz_wqn4WYY8PX15jMnLeHZgmpQd8Ua5v0u1rV4It63lM0CfwvcS85wHTRnz08QntCeoR8gA-j9SRVQc_X45Nnbpshdvct2A/file\n",
            "Reusing existing connection to uccfc57de5410deefc5c61ab8a0e.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 973130 (950K) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>] 950.32K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-07-05 06:59:41 (12.1 MB/s) - ‘data.zip’ saved [973130/973130]\n",
            "\n",
            "Archive:  data.zip\n",
            "replace /content/data/dataset/test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget -O data.zip https://www.dropbox.com/s/d4kee6t0e9l8e1r/data.zip?dl=0\n",
        "!unzip data.zip -d /content/data\n",
        "!mkdir -p /content/model/word2vec/train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv5qz5nDetm6"
      },
      "source": [
        "## 1.2. Download glove-wiki-gigaword word vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0LvBeGrJICz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c022cd-017d-4a70-d497-26371a8df9b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-05 06:59:44--  https://www.dropbox.com/s/0270psualjeh0vy/glove.6B.50d.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/0270psualjeh0vy/glove.6B.50d.zip [following]\n",
            "--2022-07-05 06:59:44--  https://www.dropbox.com/s/raw/0270psualjeh0vy/glove.6B.50d.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc04b3e2fc44df958464d0f383d7.dl.dropboxusercontent.com/cd/0/inline/Bofh9K1C4TdlStz96smtoEm-Yimtp04iSjp_kMmUHkdRdBAO4QcCWjTle5O7NyExKuPMSUqr848ju4LAHXAf7iSltjcCJi7nUPaBxRFTIIybE5eDKwO0v7xDRgyrZ8W_hCfBiZ4F5blpvjN9Kzh3znb36LRfE-FKyoA71An8-GUeXQ/file# [following]\n",
            "--2022-07-05 06:59:45--  https://uc04b3e2fc44df958464d0f383d7.dl.dropboxusercontent.com/cd/0/inline/Bofh9K1C4TdlStz96smtoEm-Yimtp04iSjp_kMmUHkdRdBAO4QcCWjTle5O7NyExKuPMSUqr848ju4LAHXAf7iSltjcCJi7nUPaBxRFTIIybE5eDKwO0v7xDRgyrZ8W_hCfBiZ4F5blpvjN9Kzh3znb36LRfE-FKyoA71An8-GUeXQ/file\n",
            "Resolving uc04b3e2fc44df958464d0f383d7.dl.dropboxusercontent.com (uc04b3e2fc44df958464d0f383d7.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc04b3e2fc44df958464d0f383d7.dl.dropboxusercontent.com (uc04b3e2fc44df958464d0f383d7.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Bod7KKasq4J_Vb1l1DxyoOP4ibaEKHLJj-g0_PG5QbW_XQFpIVyWwG_zo1vPd8SRMRurX7Y1dcvSqJ2axd_vLAmZOhM_uZ3EWKZR49Vo8h4FdFAm6LSVD0LXrMBHxyN9A6zwYnKRy2BrfMy0oH5vQQtBevXIsScT725vmDcx7Bzm-5_MDxV2RHvfHf4mVCoYT5Joz5mWjGIGKNjRcJowoTcdcLNNgmeKYWq1ssQMpe3muTh0Byozpx_1V9sZ6LbmQaCtd1KcvsaKMURZDzJKxeOK7GUH1bo6BKZu6lOjOZDUPyoaJRz5zxPqMEB1eD-VapThhm2dOjwLBDyfaRPMqS7uwUrXeH-ChieoWAWGAlWqmLv32QDp65pmvAECkClVf68A9x7oAkXejfQFMKScavijW9Q8Et2j6VU2A9DCYWTtIg/file [following]\n",
            "--2022-07-05 06:59:45--  https://uc04b3e2fc44df958464d0f383d7.dl.dropboxusercontent.com/cd/0/inline2/Bod7KKasq4J_Vb1l1DxyoOP4ibaEKHLJj-g0_PG5QbW_XQFpIVyWwG_zo1vPd8SRMRurX7Y1dcvSqJ2axd_vLAmZOhM_uZ3EWKZR49Vo8h4FdFAm6LSVD0LXrMBHxyN9A6zwYnKRy2BrfMy0oH5vQQtBevXIsScT725vmDcx7Bzm-5_MDxV2RHvfHf4mVCoYT5Joz5mWjGIGKNjRcJowoTcdcLNNgmeKYWq1ssQMpe3muTh0Byozpx_1V9sZ6LbmQaCtd1KcvsaKMURZDzJKxeOK7GUH1bo6BKZu6lOjOZDUPyoaJRz5zxPqMEB1eD-VapThhm2dOjwLBDyfaRPMqS7uwUrXeH-ChieoWAWGAlWqmLv32QDp65pmvAECkClVf68A9x7oAkXejfQFMKScavijW9Q8Et2j6VU2A9DCYWTtIg/file\n",
            "Reusing existing connection to uc04b3e2fc44df958464d0f383d7.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 69919231 (67M) [application/zip]\n",
            "Saving to: ‘glove_6B_50d_txt.zip’\n",
            "\n",
            "glove_6B_50d_txt.zi 100%[===================>]  66.68M  26.8MB/s    in 2.5s    \n",
            "\n",
            "2022-07-05 06:59:49 (26.8 MB/s) - ‘glove_6B_50d_txt.zip’ saved [69919231/69919231]\n",
            "\n",
            "Archive:  glove_6B_50d_txt.zip\n",
            "replace /content/glove_6B_50d_txt/glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget -O glove_6B_50d_txt.zip https://www.dropbox.com/s/0270psualjeh0vy/glove.6B.50d.zip?dl=0\n",
        "!unzip glove_6B_50d_txt.zip -d /content/glove_6B_50d_txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pitTghKbfLPA"
      },
      "source": [
        "## 1.3. Download nltk modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVpQeBgWfRq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f899181-6596-4624-fa67-0aaa8812d31f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IBgQOIIfkxI"
      },
      "source": [
        "# 2. Importing Common Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYC-5HGQoq1t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4faGG-9of9KK"
      },
      "source": [
        "# 3. Read Train and Test Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSkIS-MoscvA"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('/content/data/dataset/train.csv')\n",
        "test_data = pd.read_csv('/content/data/dataset/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDTyhe7F_0Dz"
      },
      "outputs": [],
      "source": [
        "result_accuracy = []\n",
        "result_accuracy_label = []\n",
        "WV_SIZE = 50\n",
        "OUTPUT_FOLDER = '/content/model/word2vec/train/'\n",
        "word2vec_filename = OUTPUT_FOLDER + 'train_review_word2vec.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL5_XCOlriE5"
      },
      "source": [
        "# 4. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWDiTqvFgFJd"
      },
      "outputs": [],
      "source": [
        "extra_punct = [\n",
        "    ',', '.', '\"', ':', ')', '(', '!', '?', '|', ';', \"'\", '$', '&',\n",
        "    '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
        "    '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',\n",
        "    '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n",
        "    '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾',\n",
        "    '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n",
        "    '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
        "    'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n",
        "    '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
        "    '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQ_W2pAmgIwS"
      },
      "outputs": [],
      "source": [
        "class Preprocessor():\n",
        "  def __init__(self):\n",
        "    self.stopwords = nltk.corpus.stopwords.words('english')\n",
        "    self.wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "  def remove_extra_space(self, text):\n",
        "    text = text.replace('\\\\t', ' ')\n",
        "    text = text.replace('\\\\n', ' ')\n",
        "    return text\n",
        "\n",
        "  def remove_url(self, text):\n",
        "    return re.sub(r\"http\\S+\", \" \", text)\n",
        "\n",
        "  def remove_punctuation(self, text):\n",
        "    punctuationfree = \"\"\n",
        "    for i in text:\n",
        "      if i in string.punctuation or i in extra_punct:\n",
        "        punctuationfree += \" \"\n",
        "      else:\n",
        "        punctuationfree += i\n",
        "    return punctuationfree\n",
        "\n",
        "  def tokenization(self, text):\n",
        "    text = text.replace('\\t', ' ')\n",
        "    text = text.replace('\\n', ' ')\n",
        "    tokens = text.split(' ')\n",
        "    if '' in tokens:\n",
        "      tokens.remove('')\n",
        "    return tokens\n",
        "\n",
        "  def remove_stopwords(self, text):\n",
        "    output= [i for i in text if i not in self.stopwords]\n",
        "    return output\n",
        "\n",
        "  def lemmatizer(self, text):\n",
        "    lemm_text = [self.wordnet_lemmatizer.lemmatize(word) for word in text]\n",
        "    if '' in lemm_text:\n",
        "      lemm_text = [value for value in lemm_text if value != '']\n",
        "\n",
        "    return lemm_text\n",
        "\n",
        "  def join_sent(self, text):\n",
        "    return \" \".join(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8mntLt4hc3N"
      },
      "outputs": [],
      "source": [
        "def preprocess_documents(data, source_col, target_col):\n",
        "  processor = Preprocessor()\n",
        "  data[source_col + '_extra_space'] = data[source_col].apply(lambda x:processor.remove_extra_space(x))\n",
        "\n",
        "  data[source_col + '_no_url'] = data[source_col + '_extra_space'].apply(lambda x:processor.remove_url(x))\n",
        "\n",
        "  data[source_col + '_no_punc'] = data[source_col + '_no_url'].apply(lambda x:processor.remove_punctuation(x))\n",
        "  data[source_col + '_lower'] = data[source_col + '_no_punc'].apply(lambda x: x.lower())\n",
        "\n",
        "  data[source_col + '_lower'].replace('', np.nan, inplace=True)\n",
        "  data = data.dropna()\n",
        "\n",
        "  data[source_col + '_tokenized'] = data[source_col + '_lower'] .apply(lambda x: processor.tokenization(x))\n",
        "  data[source_col + '_no_stopword'] = data[source_col + '_tokenized'].apply(lambda x: processor.remove_stopwords(x))\n",
        "  data[target_col] = data[source_col + '_no_stopword'].apply(lambda x: processor.lemmatizer(x))\n",
        "  data[source_col + '_clean'] = data[source_col + '_no_stopword'].apply(lambda x: processor.join_sent(x))\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSpwMGw-jkR1"
      },
      "outputs": [],
      "source": [
        "train_data = preprocess_documents(train_data, 'Comment', 'msg_lemmatized')\n",
        "test_data = preprocess_documents(test_data, 'Comment', 'msg_lemmatized')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhLu7suqsU0B"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_data['topic_labels'] = label_encoder.fit_transform(train_data['Topic'])\n",
        "test_data['topic_labels'] = label_encoder.transform(test_data['Topic'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXFvGyrjjzsd"
      },
      "source": [
        "# 5. Make a Word2Vec Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB6pcb5Vj78e"
      },
      "outputs": [],
      "source": [
        "def build_word2vec_from_pretrained(sentences, wv_size, w2v_formant_fn):\n",
        "  model = Word2Vec(size=wv_size, min_count=1)\n",
        "  model.build_vocab(sentences)\n",
        "  total_examples = model.corpus_count\n",
        "\n",
        "  pretrained_w2v = KeyedVectors.load_word2vec_format(w2v_formant_fn, binary=False)\n",
        "  model.build_vocab([list(pretrained_w2v.vocab.keys())], update=True)\n",
        "\n",
        "  model.intersect_word2vec_format(w2v_formant_fn, binary=False, lockf=1.0)\n",
        "  model.train(sentences, total_examples=total_examples, epochs=model.iter)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYnXKnXMlNO8",
        "outputId": "b07c9467-0d94-404d-f8bc-24d95561c9c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ],
      "source": [
        "sentences = train_data['msg_lemmatized'].values\n",
        "test_sentences = test_data['msg_lemmatized'].values\n",
        "word2vec_model = build_word2vec_from_pretrained(np.concatenate((sentences, test_sentences), axis=0), 50, \"/content/glove_6B_50d_txt/glove.6B.50d.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzfK8u6Cqsbz"
      },
      "outputs": [],
      "source": [
        "def generate_w2v_vector_file(data, target_col, word2vec_filename, w2v_model):\n",
        "  with open(word2vec_filename, 'w') as word2vec_file:\n",
        "      for index, row in data.iterrows():\n",
        "          # print(row['msg_lemmatized'])\n",
        "          model_vector = (np.mean([w2v_model[token] for token in row[target_col]], axis=0)).tolist()\n",
        "          if index == 0:\n",
        "              header = \",\".join(str(ele) for ele in range(WV_SIZE))\n",
        "              word2vec_file.write(header)\n",
        "              word2vec_file.write(\"\\n\")\n",
        "          # Check if the line exists else it is vector of zeros\n",
        "          if type(model_vector) is list:\n",
        "              line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n",
        "          else:\n",
        "              line1 = \",\".join([str(0) for i in range(WV_SIZE)])\n",
        "          word2vec_file.write(line1)\n",
        "          word2vec_file.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkSniKu8ncAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815def3a-87ab-44a2-e305-33390d5610ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ],
      "source": [
        "generate_w2v_vector_file(train_data, 'msg_lemmatized', word2vec_filename, word2vec_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgbfQjto150d"
      },
      "source": [
        "# 6. Classification Only with Word2Vec Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7e8uFJZqJeP"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "word2vec_df = pd.read_csv(word2vec_filename)\n",
        "dtc_word2vec = DecisionTreeClassifier()\n",
        "dtc_word2vec = dtc_word2vec.fit(word2vec_df, train_data['topic_labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LkxdlBz2-Y3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b9be66-c4fb-4517-ef71-7a8760522e1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       614\n",
            "           1       0.32      1.00      0.48       506\n",
            "           2       0.00      0.00      0.00       466\n",
            "\n",
            "    accuracy                           0.32      1586\n",
            "   macro avg       0.11      0.33      0.16      1586\n",
            "weighted avg       0.10      0.32      0.15      1586\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test_features_word2vec = []\n",
        "for index, row in test_data.iterrows():\n",
        "  model_vector = np.mean([word2vec_model[token] for token in row['msg_lemmatized']], axis=0)\n",
        "  if type(model_vector) is list:\n",
        "    test_features_word2vec.append(model_vector)\n",
        "  else:\n",
        "    test_features_word2vec.append(np.array([0 for i in range(WV_SIZE)]))\n",
        "\n",
        "test_predictions_word2vec = dtc_word2vec.predict(test_features_word2vec)\n",
        "print(classification_report(test_data['topic_labels'],test_predictions_word2vec))\n",
        "result_accuracy.append(accuracy_score(test_data['topic_labels'], test_predictions_word2vec))\n",
        "result_accuracy_label.append('only-word2vec-mean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq4pTB4J87Lf"
      },
      "source": [
        "# 7. Classification Only with Bag-of-Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz2y265c7P_4"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "vect = CountVectorizer(max_features= None)\n",
        "X_train_dtm = vect.fit_transform(train_data['Comment_clean'].values)\n",
        "X_test_dtm = vect.transform(test_data['Comment_clean'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NF9NMkKz_bVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62fc25d9-0595-49ab-a271-224a3ce545c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.80      0.81       614\n",
            "           1       0.76      0.76      0.76       506\n",
            "           2       0.78      0.79      0.78       466\n",
            "\n",
            "    accuracy                           0.78      1586\n",
            "   macro avg       0.78      0.78      0.78      1586\n",
            "weighted avg       0.79      0.78      0.79      1586\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svm = LinearSVC().fit(X_train_dtm, train_data['topic_labels'])\n",
        "y_pred = svm.predict(X_test_dtm)\n",
        "print(classification_report(test_data['topic_labels'],y_pred))\n",
        "result_accuracy.append(accuracy_score(test_data['topic_labels'], y_pred))\n",
        "result_accuracy_label.append('only-bag-of-words')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQUbKamkEa6a"
      },
      "source": [
        "# 8. Classification with Combined Prediction of two Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7uIFkGh6Ie1"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "def load_vector_lookup(embeddings_index):\n",
        "\n",
        "    emb_ind = {}\n",
        "    for i, vec in tqdm(enumerate(embeddings_index.wv.vectors)):\n",
        "        emb_ind[embeddings_index.wv.index2word[i]] = vec\n",
        "    del embeddings_index\n",
        "    gc.collect()\n",
        "    return emb_ind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB1eIHMI8Yi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea2c5dc-23a5-4c98-8e41-2ec8c813e5b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "402299it [00:00, 827532.85it/s]\n"
          ]
        }
      ],
      "source": [
        "vector_lookup  = load_vector_lookup(word2vec_model)\n",
        "null_vector = vector_lookup['the']\n",
        "\n",
        "def make_bov(sentence):\n",
        "  sent_vec = np.zeros((50))\n",
        "  sentence = sentence.split()\n",
        "  sent_length = len(sentence) + 1\n",
        "  for word in sentence:\n",
        "      try:\n",
        "          sent_vec += vector_lookup[word.lower()]\n",
        "      except:\n",
        "          sent_vec += null_vector\n",
        "  sent_vec /= sent_length\n",
        "  return sent_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyIMfDjnx6K_"
      },
      "outputs": [],
      "source": [
        "class Word2VecDecisionTreeClassifier(DecisionTreeClassifier):\n",
        "  def __init__(\n",
        "      self,\n",
        "      *,\n",
        "      criterion=\"gini\",\n",
        "      splitter=\"best\",\n",
        "      max_depth=None,\n",
        "      min_samples_split=2,\n",
        "      min_samples_leaf=1,\n",
        "      min_weight_fraction_leaf=0.0,\n",
        "      max_features=None,\n",
        "      random_state=None,\n",
        "      max_leaf_nodes=None,\n",
        "      min_impurity_decrease=0.0,\n",
        "      class_weight=None,\n",
        "      ccp_alpha=0.0,\n",
        "  ):\n",
        "    super().__init__(\n",
        "              criterion=criterion,\n",
        "              splitter=splitter,\n",
        "              max_depth=max_depth,\n",
        "              min_samples_split=min_samples_split,\n",
        "              min_samples_leaf=min_samples_leaf,\n",
        "              min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
        "              max_features=max_features,\n",
        "              max_leaf_nodes=max_leaf_nodes,\n",
        "              class_weight=class_weight,\n",
        "              random_state=random_state,\n",
        "              min_impurity_decrease=min_impurity_decrease,\n",
        "              ccp_alpha=ccp_alpha,\n",
        "    )\n",
        "\n",
        "  def fit(self, X, y, sample_weight=None, check_input=True):\n",
        "    # global word2vec_filename\n",
        "    # X = pd.read_csv(word2vec_filename)\n",
        "    global train_data\n",
        "    train_features = np.array([make_bov(sent) for sent in train_data[\"Comment_clean\"].values])\n",
        "    super().fit(train_features, y, sample_weight, check_input)\n",
        "    return self\n",
        "\n",
        "  def predict(self, X, check_input=True):\n",
        "    # global test_features_word2vec\n",
        "    # X = test_features_word2vec\n",
        "    global test_data\n",
        "    test_features = np.array([make_bov(sent) for sent in test_data[\"Comment_clean\"].values])\n",
        "    return super().predict(test_features, check_input)\n",
        "\n",
        "  def predict_proba(self, X):\n",
        "    global test_features_word2vec\n",
        "    X = test_features_word2vec\n",
        "    return super().predict_proba(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Anu34EsnzS-L"
      },
      "outputs": [],
      "source": [
        "class BagOfWordSVM(LinearSVC):\n",
        "  def __init__(self,\n",
        "        penalty=\"l2\",\n",
        "        loss=\"squared_hinge\",\n",
        "        *,\n",
        "        dual=True,\n",
        "        tol=1e-4,\n",
        "        C=1.0,\n",
        "        multi_class=\"ovr\",\n",
        "        fit_intercept=True,\n",
        "        intercept_scaling=1,\n",
        "        class_weight=None,\n",
        "        verbose=0,\n",
        "        random_state=None,\n",
        "        max_iter=1000,\n",
        "  ):\n",
        "    super().__init__(\n",
        "        penalty=penalty,\n",
        "          loss=loss,\n",
        "          dual=dual,\n",
        "          tol=tol,\n",
        "          C=C,\n",
        "          multi_class=multi_class,\n",
        "          fit_intercept=fit_intercept,\n",
        "          intercept_scaling=intercept_scaling,\n",
        "          class_weight=class_weight,\n",
        "          verbose=verbose,\n",
        "          random_state=random_state,\n",
        "          max_iter=max_iter\n",
        "    )\n",
        "\n",
        "  def fit(self, X, y, sample_weight=None):\n",
        "    self.vect = CountVectorizer(max_features= 5000)\n",
        "    X = self.vect.fit_transform(X['Comment_clean'].values)\n",
        "    super().fit(X, y, sample_weight)\n",
        "    return self\n",
        "\n",
        "  def predict(self, X):\n",
        "    X = self.vect.transform(X['Comment_clean'].values)\n",
        "    return super().predict(X)\n",
        "\n",
        "  def predict_proba(self, X):\n",
        "    X = self.vect.transform(X['Comment_clean'].values)\n",
        "    return super().predict_proba(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFwCY-6B3yfK"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "class VottingClassifierWrapper(VotingClassifier):\n",
        "  def __init__(self,\n",
        "        estimators,\n",
        "        *,\n",
        "        voting=\"hard\",\n",
        "        weights=None,\n",
        "        n_jobs=None,\n",
        "        flatten_transform=True,\n",
        "        verbose=False):\n",
        "    super().__init__(\n",
        "        estimators,\n",
        "        voting=voting,\n",
        "        weights=weights,\n",
        "        n_jobs=n_jobs,\n",
        "        flatten_transform=flatten_transform,\n",
        "        verbose=verbose\n",
        "    )\n",
        "\n",
        "  def predict(self, X):\n",
        "    predictions = self._predict(X)\n",
        "    maj = np.apply_along_axis(\n",
        "        lambda x: np.argmax(np.bincount(x, weights=self._weights_not_none)),\n",
        "        axis=1,\n",
        "        arr=predictions,\n",
        "    )\n",
        "    maj = self.le_.inverse_transform(maj)\n",
        "    return maj\n",
        "\n",
        "\n",
        "  def predict_proba(self, X):\n",
        "    avg = np.average(self._collect_probas(X), axis=0, weights=self._weights_not_none)\n",
        "    return avg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpzSwDiRETEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9802856-b006-4f37-8ad4-eeba24865d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.86      0.77       614\n",
            "           1       0.62      0.67      0.64       506\n",
            "           2       0.88      0.51      0.64       466\n",
            "\n",
            "    accuracy                           0.70      1586\n",
            "   macro avg       0.73      0.68      0.69      1586\n",
            "weighted avg       0.72      0.70      0.69      1586\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "est_w2v = Word2VecDecisionTreeClassifier()\n",
        "est_bow = BagOfWordSVM()\n",
        "\n",
        "combined = VottingClassifierWrapper(estimators=[('w2v', est_w2v), ('bow', est_bow)], voting='hard', weights=['1', '1'])\n",
        "combined = combined.fit(train_data, train_data['topic_labels'])\n",
        "\n",
        "y_pred = combined.predict(test_data)\n",
        "print(classification_report(test_data['topic_labels'],y_pred))\n",
        "result_accuracy.append(accuracy_score(test_data['topic_labels'], y_pred))\n",
        "result_accuracy_label.append('combined-w2v-bow')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOmKe_-j6KLr"
      },
      "source": [
        "# 9. Bag-of-Vectors (BoV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTCt0uQo9Ce2"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "tsvd = TruncatedSVD(n_components = 30)\n",
        "\n",
        "train_features = np.array([make_bov(sent) for sent in train_data[\"Comment_clean\"].values])\n",
        "test_features = np.array([make_bov(sent) for sent in test_data[\"Comment_clean\"].values])\n",
        "\n",
        "train_features_svd = tsvd.fit_transform(train_features)\n",
        "test_features_svd = tsvd.transform(test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlDTgH6x_SRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd49268d-c13a-4afa-95a2-cb6ec00cd011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.79      0.79       614\n",
            "           1       0.69      0.75      0.72       506\n",
            "           2       0.81      0.73      0.76       466\n",
            "\n",
            "    accuracy                           0.76      1586\n",
            "   macro avg       0.76      0.76      0.76      1586\n",
            "weighted avg       0.76      0.76      0.76      1586\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svm = LinearSVC().fit(train_features, train_data['topic_labels'])\n",
        "y_pred = svm.predict(test_features)\n",
        "print(classification_report(test_data['topic_labels'],y_pred))\n",
        "result_accuracy.append(accuracy_score(test_data['topic_labels'], y_pred))\n",
        "result_accuracy_label.append('mean_w2v')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjRipWltAIt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350d0b37-7871-4692-9944-f01874c7493d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.79      0.80       614\n",
            "           1       0.70      0.73      0.71       506\n",
            "           2       0.77      0.74      0.76       466\n",
            "\n",
            "    accuracy                           0.76      1586\n",
            "   macro avg       0.76      0.75      0.75      1586\n",
            "weighted avg       0.76      0.76      0.76      1586\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svm = LinearSVC().fit(train_features_svd, train_data['topic_labels'])\n",
        "y_pred = svm.predict(test_features_svd)\n",
        "print(classification_report(test_data['topic_labels'],y_pred))\n",
        "result_accuracy.append(accuracy_score(test_data['topic_labels'], y_pred))\n",
        "result_accuracy_label.append('mean-w2v-svd')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faMK7ifLAWfW"
      },
      "source": [
        "# 10. TF-IDF and BoV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVy9U2VxCWAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47db5b8d-7330-4a7e-cc3c-60f939813dd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    things might negative  frequency dependent sel...\n",
              "1    hard believe exist particulars detect anything...\n",
              "2                                                 bees\n",
              "3    medication technician alot drugs liver  probab...\n",
              "4                                  cesium pretty metal\n",
              "Name: Comment_clean, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "train_data['Comment_clean'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1LhtUVDAV7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9744bcd1-d515-46a0-f069-b9f9a3bc48dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,1))\n",
        "tfidf_matrix =  tf.fit_transform(train_data['Comment_clean'])\n",
        "feature_names = tf.get_feature_names()\n",
        "sentences_tf_idf = []\n",
        "docs = train_data['Comment_clean'].values.shape[0]\n",
        "for doc in range(docs):\n",
        "  feature_index = tfidf_matrix[doc,:].nonzero()[1]\n",
        "  tfidf_scores = zip(feature_index, [tfidf_matrix[doc, x] for x in feature_index])\n",
        "  sentece_tf_idf = dict()\n",
        "  for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n",
        "    sentece_tf_idf[w] = s\n",
        "  sentences_tf_idf.append(sentece_tf_idf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_BckFDFDKYj"
      },
      "outputs": [],
      "source": [
        "def make_bov_tf_idf(sentence, index):\n",
        "  # print(sentence)\n",
        "  # sentence = sentence['Comment_clean'].values[0]\n",
        "  sent_vec = np.zeros((50))\n",
        "  sentence = sentence.split()\n",
        "  tf_idf = sentences_tf_idf[index]\n",
        "  sent_length = len(sentence) + 1\n",
        "  for word in sentence:\n",
        "      try:\n",
        "          sent_vec += vector_lookup[word.lower()] * tf_idf[word.lower()]\n",
        "      except:\n",
        "          sent_vec += null_vector\n",
        "  sent_vec /= sent_length\n",
        "  return sent_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJuZUEFLEw1-"
      },
      "outputs": [],
      "source": [
        "train_feat = np.zeros((train_data.values.shape[0], 50))\n",
        "for index, row in train_data.iterrows():\n",
        "  train_feat[index, :] = make_bov_tf_idf(row['Comment_clean'], index)\n",
        "\n",
        "test_feat = np.zeros((test_data.values.shape[0], 50))\n",
        "for index, row in test_data.iterrows():\n",
        "  test_feat[index, :] = make_bov_tf_idf(row['Comment_clean'], index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rz2mF-lGtfZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e97325-e1b3-4f79-f7f8-4c4eb57c2e00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       614\n",
            "           1       0.00      0.00      0.00       506\n",
            "           2       0.29      1.00      0.45       466\n",
            "\n",
            "    accuracy                           0.29      1586\n",
            "   macro avg       0.10      0.33      0.15      1586\n",
            "weighted avg       0.09      0.29      0.13      1586\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svm = LinearSVC().fit(train_feat, train_data['topic_labels'])\n",
        "y_pred = svm.predict(test_feat)\n",
        "print(classification_report(test_data['topic_labels'],y_pred))\n",
        "result_accuracy.append(accuracy_score(test_data['topic_labels'], y_pred))\n",
        "result_accuracy_label.append('combine-tfidf-w2v-mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZl3QBBct7W-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c094984e-0b83-4966-d194-796d47ec9aac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "count = CountVectorizer(max_features=None)\n",
        "\n",
        "count_matrix =  count.fit_transform(train_data['Comment_clean'])\n",
        "feature_names = count.get_feature_names()\n",
        "sentences_count = []\n",
        "docs = train_data['Comment_clean'].values.shape[0]\n",
        "for doc in range(docs):\n",
        "  feature_index = count_matrix[doc,:].nonzero()[1]\n",
        "  count_scores = zip(feature_index, [count_matrix[doc, x] for x in feature_index])\n",
        "  sentece_count = dict()\n",
        "  for w, s in [(feature_names[i], s) for (i, s) in count_scores]:\n",
        "    sentece_count[w] = s\n",
        "  sentences_count.append(sentece_tf_idf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmK_MQAwuptJ"
      },
      "outputs": [],
      "source": [
        "def make_bov_count(sentence, index):\n",
        "  # print(sentence)\n",
        "  # sentence = sentence['Comment_clean'].values[0]\n",
        "  sent_vec = np.zeros((50))\n",
        "  sentence = sentence.split()\n",
        "  count = sentences_count[index]\n",
        "  sent_length = len(sentence) + 1\n",
        "  for word in sentence:\n",
        "      try:\n",
        "          sent_vec += vector_lookup[word.lower()] * count[word.lower()] * 100\n",
        "      except:\n",
        "          sent_vec += null_vector\n",
        "  sent_vec /= sent_length\n",
        "  return sent_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X2laoJRu034"
      },
      "outputs": [],
      "source": [
        "train_feat = np.zeros((train_data.values.shape[0], 50))\n",
        "for index, row in train_data.iterrows():\n",
        "  train_feat[index, :] = make_bov_count(row['Comment_clean'], index)\n",
        "\n",
        "test_feat = np.zeros((test_data.values.shape[0], 50))\n",
        "for index, row in test_data.iterrows():\n",
        "  test_feat[index, :] = make_bov_count(row['Comment_clean'], index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdOF_UC1vFQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7535104a-403e-4e18-9254-de238d8da77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      1.00      0.56       614\n",
            "           1       0.00      0.00      0.00       506\n",
            "           2       0.00      0.00      0.00       466\n",
            "\n",
            "    accuracy                           0.39      1586\n",
            "   macro avg       0.13      0.33      0.19      1586\n",
            "weighted avg       0.15      0.39      0.22      1586\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svm = LinearSVC().fit(train_feat, train_data['topic_labels'])\n",
        "y_pred = svm.predict(test_feat)\n",
        "print(classification_report(test_data['topic_labels'],y_pred))\n",
        "result_accuracy.append(accuracy_score(test_data['topic_labels'], y_pred))\n",
        "result_accuracy_label.append('combine-frequency-w2v-mean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrx5z8PKXOt5"
      },
      "source": [
        "# 11. Bag-of-Words Using Clustered Word2Vecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEdSP3IOhzyi"
      },
      "outputs": [],
      "source": [
        "def get_w2vs_of_sentence(sentence):\n",
        "  l = []\n",
        "  sent_vec = np.zeros((50))\n",
        "  sentence = sentence.split()\n",
        "  for word in sentence:\n",
        "      try:\n",
        "          l.append(vector_lookup[word.lower()])\n",
        "      except:\n",
        "          l.append(null_vector)\n",
        "\n",
        "  return np.array(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28K3qjlCVVnn"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "\n",
        "complete_link = AgglomerativeClustering(linkage='complete')\n",
        "complete_link = complete_link.fit(word2vec_df.iloc[:, 1:].values)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (20, 15))\n",
        "plt.bar(result_accuracy_label,result_accuracy, width = 0.1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "k7-LgWq_JjVG",
        "outputId": "3cb7d24d-f3b8-489e-9b68-49fca84ae861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1080 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}